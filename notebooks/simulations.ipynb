{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d991b38",
   "metadata": {},
   "source": [
    "# Synthetic Survey Response Generation\n",
    "This notebook demonstrates how to use `generate_responses` to generate synthetic survey responses using Large Language Models (LLMs).\n",
    "\n",
    "## Overview\n",
    "The `generate_responses` function provides a complete pipeline for generating synthetic survey responses:\n",
    "\n",
    "- **LLM Integration**: Supports multiple LLM APIs (OpenAI, Anthropic, TogetherAI)\n",
    "- **Concurrent Processing**: Processes questions concurrently for efficiency\n",
    "- **Resume Capability**: Saves raw responses incrementally, allowing you to resume interrupted runs\n",
    "- **Post-Processing**: Automatically extracts structured answers from raw responses\n",
    "- **Dataset Support**: Works with two datasets:\n",
    "  - **EEDI**: Educational assessment dataset\n",
    "  - **OpinionQA**: Opinion polling dataset\n",
    "\n",
    "## Available Models\n",
    "The following LLM models are supported:\n",
    "\n",
    "**OpenAI** (`api_platform='openai'`):\n",
    "- `gpt-3.5-turbo`\n",
    "- `gpt-4o-mini`\n",
    "- `gpt-4o`\n",
    "- `gpt-5-mini`\n",
    "\n",
    "**Anthropic** (`api_platform='anthropic'`):\n",
    "- `claude-3.5-haiku`\n",
    "\n",
    "**TogetherAI** (`api_platform='togetherai'`):\n",
    "- `deepseek-v3`\n",
    "- `llama-3.3-70B-instruct-turbo`\n",
    "- `mistral-7B-instruct-v0.3`\n",
    "\n",
    "## Usage Instructions\n",
    "1. **Set your API key**: \n",
    "   - Set the `API_KEY` environment variable before running the notebook, or\n",
    "   - Modify the `api_key` variable directly in the code cell below\n",
    "\n",
    "2. **Configure parameters**: \n",
    "   - Choose your API platform (`'openai'`, `'anthropic'`, or `'togetherai'`)\n",
    "   - Select an LLM model from the list above\n",
    "   - Choose a dataset (`'EEDI'` or `'OpinionQA'`)\n",
    "   - Set the number of synthetic answers per question (max 200 for both datasets)\n",
    "   - Specify the output folder name\n",
    "\n",
    "3. **Run the cell**: Execute the `await generate_responses(...)` call\n",
    "\n",
    "4. **Check results**: \n",
    "   - Raw responses: `data/{dataset_name}/{folder_name}/raw/{llm}.json`\n",
    "   - Cleaned results: `data/{dataset_name}/{folder_name}/clean/{llm}.json`\n",
    "   - Random baseline: `data/{dataset_name}/{folder_name}/clean/random.json`\n",
    "\n",
    "## Key Parameters\n",
    "\n",
    "- **`api_platform`** (str): API platform to use. Options: `'openai'`, `'anthropic'`, `'togetherai'`\n",
    "- **`api_key`** (str): Your API key for authentication\n",
    "- **`llm`** (str): Model identifier (see available models above)\n",
    "- **`dataset_name`** (str): Dataset name. Options: `'EEDI'` or `'OpinionQA'`\n",
    "- **`first_synthetic_profile_id`** (int): Starting ID for synthetic profiles (0-200)\n",
    "- **`num_of_synthetic_answers`** (int): Number of responses per question (max 200)\n",
    "  - Note: `first_synthetic_profile_id + num_of_synthetic_answers` should not exceed 200\n",
    "- **`folder_name`** (str): Output folder name (e.g., `'synthetic_answers'` or `'synthetic_answers_testing'`)\n",
    "- **`max_concurrent_requests`** (int, optional): Number of concurrent API calls (default: 10)\n",
    "  - Higher values increase throughput but may hit rate limits\n",
    "  - For `claude-3.5-haiku`, we set it to 1 due to rate limit\n",
    "- **`max_retries`** (int, optional): Number of retry attempts for failed requests (default: 3)\n",
    "  - Uses exponential backoff (1s, 2s, 4s, ...)\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- **Resume Capability**: If raw results already exist, the function will only process questions that haven't been completed yet. This allows you to safely interrupt and resume long-running jobs.\n",
    "\n",
    "- **Processing Time**: Execution time depends on:\n",
    "  - Number of questions in the dataset\n",
    "  - Number of synthetic answers per question\n",
    "  - LLM model and API platform\n",
    "  - API rate limits\n",
    "  - Expect several hours for large runs (e.g., 100 answers × many questions)\n",
    "\n",
    "- **Error Handling**: \n",
    "  - Failed API calls are retried with exponential backoff\n",
    "  - Error responses are saved as strings starting with `\"ERROR:\"` for debugging\n",
    "  - The function continues processing even if some requests fail\n",
    "\n",
    "- **Random Baseline**: A random baseline is automatically generated with `2 × num_of_synthetic_answers` responses per question:\n",
    "  - **EEDI**: Random binary correctness scores from {0, 1}\n",
    "  - **OpinionQA**: Random opinion scores from {-1, -1/3, 0, 1/3, 1}\n",
    "\n",
    "## Output Format\n",
    "\n",
    "The cleaned results are saved as JSON files with the following structure:\n",
    "```json\n",
    "{\n",
    "  \"question_id\": [answer1, answer2, answer3, ...],\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "Where:\n",
    "- For **EEDI**: Each answer is a binary value (0 = incorrect, 1 = correct)\n",
    "- For **OpinionQA**: Each answer is a numeric score in {-1, -1/3, 0, 1/3, 1}\n",
    "\n",
    "For more details, see the function documentation in `src/simulations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup: Import required modules and configure the Python path.\n",
    "\n",
    "This cell:\n",
    "1. Finds the project root directory by locating src/simulations.py\n",
    "2. Adds the project root to sys.path so we can import from src/\n",
    "3. Imports the generate_responses function\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Find project root by walking up from current directory until we find src/simulations.py\n",
    "# This works regardless of where the notebook is run from\n",
    "cwd = os.path.abspath(os.getcwd())\n",
    "ROOT_DIR = cwd\n",
    "\n",
    "# Walk up directory tree to find the directory containing src/simulations.py\n",
    "while not os.path.exists(os.path.join(ROOT_DIR, 'src', 'simulations.py')):\n",
    "    parent = os.path.dirname(ROOT_DIR)\n",
    "    if parent == ROOT_DIR:  # Reached filesystem root\n",
    "        raise FileNotFoundError(f\"Could not find src/simulations.py. Started from: {cwd}\")\n",
    "    ROOT_DIR = parent\n",
    "\n",
    "# Add project root to Python path\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.insert(0, ROOT_DIR)\n",
    "\n",
    "# Import from src.simulations\n",
    "from src.simulations import generate_responses\n",
    "\n",
    "print(f\"\\u2705 Successfully imported generate_responses from {ROOT_DIR}/src/simulations.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration: Set your API key and configure generation parameters.\n",
    "\n",
    "IMPORTANT: Set your API key before running this cell!\n",
    "- Option 1 (Recommended): Set the API_KEY environment variable before starting Jupyter\n",
    "- Option 2: Uncomment and set api_key directly below (not recommended for security)\n",
    "\"\"\"\n",
    "# Get API key from environment variable\n",
    "api_key = os.environ.get('API_KEY')\n",
    "\n",
    "# If API_KEY is not set, you can set it directly here (not recommended for production)\n",
    "# api_key = 'your-api-key-here'\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\n",
    "        \"API key not found! Please set the API_KEY environment variable or \"\n",
    "        \"uncomment and set api_key directly in this cell.\"\n",
    "    )\n",
    "\n",
    "print(\"\\u2705 API key loaded successfully\")\n",
    "\n",
    "\"\"\"\n",
    "Generate synthetic survey responses.\n",
    "\n",
    "Progress will be displayed with a progress bar. You can safely interrupt and resume later.\n",
    "\"\"\"\n",
    "await generate_responses(\n",
    "    api_platform='openai',                   # Options: 'openai', 'anthropic', 'togetherai'\n",
    "    api_key=api_key,                         # Your API key (set above)\n",
    "    llm='gpt-4o-mini',                       # See available models in the markdown above\n",
    "    dataset_name='OpinionQA',                # Options: 'EEDI' or 'OpinionQA'\n",
    "    first_synthetic_profile_id=0,            # Starting profile ID (0-200)\n",
    "    num_of_synthetic_answers=100,            # Number of answers per question (max 200)\n",
    "    folder_name='synthetic_answers_testing', # Output folder name\n",
    "    max_concurrent_requests=10,              # Concurrent API calls (default: 10)\n",
    "    max_retries=3                            # Retry attempts for failed requests (default: 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0470c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
